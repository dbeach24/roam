{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution\n",
    "\n",
    "Most of this code is from [In Raw Numpy: t-SNE](https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_squared_euc_dists(X):\n",
    "    \"\"\"Compute matrix containing negative squared euclidean\n",
    "    distance for all pairs of points in input matrix X\n",
    "\n",
    "    # Arguments:\n",
    "        X: matrix of size NxD\n",
    "    # Returns:\n",
    "        NxN matrix D, with entry D_ij = negative squared\n",
    "        euclidean distance between rows X_i and X_j\n",
    "    \"\"\"\n",
    "    # Math? See https://stackoverflow.com/questions/37009647\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    return -D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X, diag_zero=True):\n",
    "    \"\"\"Take softmax of each row of matrix X.\"\"\"\n",
    "\n",
    "    # Subtract max for numerical stability\n",
    "    e_x = np.exp(X - np.max(X, axis=1).reshape([-1, 1]))\n",
    "\n",
    "    # We usually want diagonal probailities to be 0.\n",
    "    if diag_zero:\n",
    "        np.fill_diagonal(e_x, 0.)\n",
    "\n",
    "    # Add a tiny constant for stability of log we take later\n",
    "    e_x = e_x + 1e-8  # numerical stability\n",
    "\n",
    "    return e_x / e_x.sum(axis=1).reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob_matrix(distances, sigmas=None):\n",
    "    \"\"\"Convert a distances matrix to a matrix of probabilities.\"\"\"\n",
    "    if sigmas is not None:\n",
    "        two_sig_sq = 2. * np.square(sigmas.reshape((-1, 1)))\n",
    "        return softmax(distances / two_sig_sq)\n",
    "    else:\n",
    "        return softmax(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(eval_fn, target, tol=1e-10, max_iter=10000, \n",
    "                  lower=1e-20, upper=1000.):\n",
    "    \"\"\"Perform a binary search over input values to eval_fn.\n",
    "    \n",
    "    # Arguments\n",
    "        eval_fn: Function that we are optimising over.\n",
    "        target: Target value we want the function to output.\n",
    "        tol: Float, once our guess is this close to target, stop.\n",
    "        max_iter: Integer, maximum num. iterations to search for.\n",
    "        lower: Float, lower bound of search range.\n",
    "        upper: Float, upper bound of search range.\n",
    "    # Returns:\n",
    "        Float, best input value to function found during search.\n",
    "    \"\"\"\n",
    "    for i in range(max_iter):\n",
    "        guess = (lower + upper) / 2.\n",
    "        val = eval_fn(guess)\n",
    "        if val > target:\n",
    "            upper = guess\n",
    "        else:\n",
    "            lower = guess\n",
    "        if np.abs(val - target) <= tol:\n",
    "            break\n",
    "    return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perplexity(prob_matrix):\n",
    "    \"\"\"Calculate the perplexity of each row \n",
    "    of a matrix of probabilities.\"\"\"\n",
    "    entropy = -np.sum(prob_matrix * np.log2(prob_matrix), 1)\n",
    "    perplexity = 2 ** entropy\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def perplexity(distances, sigmas):\n",
    "    \"\"\"Wrapper function for quick calculation of \n",
    "    perplexity over a distance matrix.\"\"\"\n",
    "    return calc_perplexity(calc_prob_matrix(distances, sigmas))\n",
    "\n",
    "\n",
    "def find_optimal_sigmas(distances, target_perplexity):\n",
    "    \"\"\"For each row of distances matrix, find sigma that results\n",
    "    in target perplexity for that role.\"\"\"\n",
    "    sigmas = [] \n",
    "    # For each row of the matrix (each point in our dataset)\n",
    "    for i in range(distances.shape[0]):\n",
    "        # Make fn that returns perplexity of this row given sigma\n",
    "        eval_fn = lambda sigma: \\\n",
    "            perplexity(distances[i:i+1, :], np.array(sigma))\n",
    "        # Binary search over sigmas to achieve target perplexity\n",
    "        correct_sigma = binary_search(eval_fn, target_perplexity)\n",
    "        # Append the resulting sigma to our output array\n",
    "        sigmas.append(correct_sigma)\n",
    "    return np.array(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_joint(Y):\n",
    "    \"\"\"Given low-dimensional representations Y, compute\n",
    "    matrix of joint probabilities with entries q_ij.\"\"\"\n",
    "    # Get the distances from every point to every other\n",
    "    distances = neg_squared_euc_dists(Y)\n",
    "    # Take the elementwise exponent\n",
    "    exp_distances = np.exp(distances)\n",
    "    # Fill diagonal with zeroes so q_ii = 0\n",
    "    np.fill_diagonal(exp_distances, 0.)\n",
    "    # Divide by the sum of the entire exponentiated matrix\n",
    "    return exp_distances / np.sum(exp_distances), None\n",
    "\n",
    "\n",
    "def p_conditional_to_joint(P):\n",
    "    \"\"\"Given conditional probabilities matrix P, return\n",
    "    approximation of joint distribution probabilities.\"\"\"\n",
    "    return (P + P.T) / (2. * P.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_joint(X, target_perplexity):\n",
    "    \"\"\"Given a data matrix X, gives joint probabilities matrix.\n",
    "\n",
    "    # Arguments\n",
    "        X: Input data matrix.\n",
    "    # Returns:\n",
    "        P: Matrix with entries p_ij = joint probabilities.\n",
    "    \"\"\"\n",
    "    # Get the negative euclidian distances matrix for our data\n",
    "    distances = neg_squared_euc_dists(X)\n",
    "    # Find optimal sigma for each row of this distances matrix\n",
    "    sigmas = find_optimal_sigmas(distances, target_perplexity)\n",
    "    # Calculate the probabilities based on these optimal sigmas\n",
    "    p_conditional = calc_prob_matrix(distances, sigmas)\n",
    "    # Go from conditional to joint probabilities matrix\n",
    "    P = p_conditional_to_joint(p_conditional)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_sne_grad(P, Q, Y, _):\n",
    "    \"\"\"Estimate the gradient of the cost with respect to Y\"\"\"\n",
    "    pq_diff = P - Q  # NxN matrix\n",
    "    pq_expanded = np.expand_dims(pq_diff, 2)  #NxNx1\n",
    "    y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)  #NxNx2\n",
    "    grad = 4. * (pq_expanded * y_diffs).sum(1)  #Nx2\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sne(P, q_fn, grad_fn,\n",
    "                 num_iters=500,\n",
    "                 learning_rate=10.0,\n",
    "                 momentum=0.9):\n",
    "    \"\"\"Estimates a SNE model.\n",
    "\n",
    "    # Arguments\n",
    "        P: Matrix of joint probabilities.\n",
    "        num_iters: Iterations to train for.\n",
    "        q_fn: Function that takes Y and gives Q prob matrix.\n",
    "        grad_fn: Function to compute gradient cost, given (P, Q, Y, inv_distances)\n",
    "    # Returns:\n",
    "        Y: Matrix, low-dimensional representation of X.\n",
    "    \"\"\"\n",
    "    \n",
    "    N, M = P.shape\n",
    "    assert N == M, \"P must be a square matrix\"\n",
    "    \n",
    "    # Initialise our 2D representation\n",
    "    Y = np.random.normal(0., 0.0001, [N, 2])\n",
    "\n",
    "    # Initialise past values (used for momentum)\n",
    "    if momentum:\n",
    "        Y_m2 = Y.copy()\n",
    "        Y_m1 = Y.copy()\n",
    "\n",
    "    # Start gradient descent loop\n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Get Q and distances (distances only used for t-SNE)\n",
    "        Q, distances = q_fn(Y)\n",
    "        # Estimate gradients with respect to Y\n",
    "        grads = grad_fn(P, Q, Y, distances)\n",
    "\n",
    "        # Update Y\n",
    "        Y -= learning_rate * grads\n",
    "        if momentum:  # Add momentum\n",
    "            Y += momentum * (Y_m1 - Y_m2)\n",
    "            # Update previous Y's for momentum\n",
    "            Y_m2 = Y_m1.copy()\n",
    "            Y_m1 = Y.copy()\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_tsne(Y):\n",
    "    \"\"\"t-SNE: Given low-dimensional representations Y, compute\n",
    "    matrix of joint probabilities with entries q_ij.\"\"\"\n",
    "    distances = neg_squared_euc_dists(Y)\n",
    "    inv_distances = np.power(1. - distances, -1)\n",
    "    np.fill_diagonal(inv_distances, 0.)\n",
    "    return inv_distances / np.sum(inv_distances), inv_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_grad(P, Q, Y, inv_distances):\n",
    "    \"\"\"Estimate the gradient of t-SNE cost with respect to Y.\"\"\"\n",
    "    pq_diff = P - Q\n",
    "    pq_expanded = np.expand_dims(pq_diff, 2)\n",
    "    y_diffs = np.expand_dims(Y, 1) - np.expand_dims(Y, 0)\n",
    "\n",
    "    # Expand our inv_distances matrix so can multiply by y_diffs\n",
    "    distances_expanded = np.expand_dims(inv_distances, 2)\n",
    "\n",
    "    # Multiply this by inverse distances matrix\n",
    "    y_diffs_wt = y_diffs * distances_expanded\n",
    "\n",
    "    # Multiply then sum over j's\n",
    "    grad = 4. * (pq_expanded * y_diffs_wt).sum(1)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tsne(P,\n",
    "                  num_iters=500,\n",
    "                  learning_rate=10.0,\n",
    "                  momentum=0.9):\n",
    "    return estimate_sne(P, q_fn=q_tsne, grad_fn=tsne_grad,\n",
    "                       num_iters=num_iters,\n",
    "                       learning_rate=learning_rate,\n",
    "                       momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 516.57588889,  244.14749055],\n",
       "       [ 346.98265088,  234.87590968],\n",
       "       [  57.87192197,   73.74492006]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.array([[0.0, 0.1, 0.2], [0.5, 0.0, 0.1], [0.05, 0.05, 0.0]])\n",
    "Y = estimate_tsne(P)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10c4d5358>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c3f7630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y[:,0], Y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
